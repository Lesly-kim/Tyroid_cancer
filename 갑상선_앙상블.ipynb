{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95673ce8-297e-4c7e-beb5-1eb90fb9991f",
   "metadata": {},
   "source": [
    "### Test_03 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "807433f1-dbcd-4769-b7c3-44d399a1ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a731a-8455-4d54-8c36-fb19ca4b6510",
   "metadata": {},
   "source": [
    "- train.csv [파일]\n",
    "```\n",
    "ID : 샘플별 고유 ID\n",
    "Age : 환자의 나이\n",
    "Gender : 성별\n",
    "Country : 국적\n",
    "Race : 인종\n",
    "Family_Background : 가족력 여부\n",
    "Radiation_History : 방사선 노출 이력\n",
    "Iodine_Deficiency : 요오드 결핍 여부\n",
    "Smoke : 흡연 여부\n",
    "Weight_Risk : 체중 관련 위험도\n",
    "Diabetes : 당뇨병 여부\n",
    "Nodule_Size : 갑상선 결절 크기\n",
    "TSH_Result : TSH 호르몬 검사 결과\n",
    "T4_Result : T4 호르몬 검사 결과\n",
    "T3_Result : T3 호르몬 검사 결과\n",
    "Cancer : 갑상선암 여부 (0: 양성, 1: 악성)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49901d9f-c09b-4734-bb31-3ed860838d89",
   "metadata": {},
   "source": [
    "### 범주형 데이터인 변수\n",
    "```\n",
    "Gender : 성별\n",
    "Country : 국적\n",
    "Race : 인종\n",
    "Family_Background : 가족력 여부\n",
    "Radiation_History : 방사선 노출 이력\n",
    "Iodine_Deficiency : 요오드 결핍 여부\n",
    "Smoke : 흡연 여부\n",
    "Weight_Risk : 체중 관련 위험도\n",
    "Diabetes : 당뇨병 여부\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066e6b85-612b-4d78-a36d-3b6164e1a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터\n",
    "train = pd.read_csv('open/train.csv')\n",
    "# 검증 데이터\n",
    "test = pd.read_csv('open/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "284df81e-0a9a-4f7a-8264-2d31c1259e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cancer\n",
       "0    0.880001\n",
       "1    0.119999\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cancer'].value_counts(normalize=True)\n",
    "# 0 : 양성, 1: 악성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d5dde3-5c80-4b07-8ed0-ea62e37eed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갑상선암 진단 학습 데이터셋 크기 :  (87159, 16)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87159 entries, 0 to 87158\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 87159 non-null  object \n",
      " 1   Age                87159 non-null  int64  \n",
      " 2   Gender             87159 non-null  object \n",
      " 3   Country            87159 non-null  object \n",
      " 4   Race               87159 non-null  object \n",
      " 5   Family_Background  87159 non-null  object \n",
      " 6   Radiation_History  87159 non-null  object \n",
      " 7   Iodine_Deficiency  87159 non-null  object \n",
      " 8   Smoke              87159 non-null  object \n",
      " 9   Weight_Risk        87159 non-null  object \n",
      " 10  Diabetes           87159 non-null  object \n",
      " 11  Nodule_Size        87159 non-null  float64\n",
      " 12  TSH_Result         87159 non-null  float64\n",
      " 13  T4_Result          87159 non-null  float64\n",
      " 14  T3_Result          87159 non-null  float64\n",
      " 15  Cancer             87159 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(10)\n",
      "memory usage: 10.6+ MB\n"
     ]
    }
   ],
   "source": [
    "print('갑상선암 진단 학습 데이터셋 크기 : ', train.shape)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083fef6-a9aa-40fb-a0ff-4a10a9216943",
   "metadata": {},
   "source": [
    "### 데이터 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "580c658a-c312-4653-8862-ab8a7336c149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87159 entries, 0 to 87158\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 87159 non-null  object \n",
      " 1   Age                87159 non-null  int64  \n",
      " 2   Gender             87159 non-null  int64  \n",
      " 3   Family_Background  87159 non-null  int64  \n",
      " 4   Radiation_History  87159 non-null  int64  \n",
      " 5   Iodine_Deficiency  87159 non-null  int64  \n",
      " 6   Smoke              87159 non-null  int64  \n",
      " 7   Weight_Risk        87159 non-null  int64  \n",
      " 8   Diabetes           87159 non-null  int64  \n",
      " 9   Nodule_Size        87159 non-null  float64\n",
      " 10  TSH_Result         87159 non-null  float64\n",
      " 11  T4_Result          87159 non-null  float64\n",
      " 12  T3_Result          87159 non-null  float64\n",
      " 13  Country_BRA        87159 non-null  bool   \n",
      " 14  Country_CHN        87159 non-null  bool   \n",
      " 15  Country_DEU        87159 non-null  bool   \n",
      " 16  Country_GBR        87159 non-null  bool   \n",
      " 17  Country_IND        87159 non-null  bool   \n",
      " 18  Country_JPN        87159 non-null  bool   \n",
      " 19  Country_KOR        87159 non-null  bool   \n",
      " 20  Country_NGA        87159 non-null  bool   \n",
      " 21  Country_RUS        87159 non-null  bool   \n",
      " 22  Country_USA        87159 non-null  bool   \n",
      " 23  Race_AFR           87159 non-null  bool   \n",
      " 24  Race_ASN           87159 non-null  bool   \n",
      " 25  Race_CAU           87159 non-null  bool   \n",
      " 26  Race_HSP           87159 non-null  bool   \n",
      " 27  Race_MDE           87159 non-null  bool   \n",
      " 28  Cancer             87159 non-null  int64  \n",
      "dtypes: bool(15), float64(4), int64(9), object(1)\n",
      "memory usage: 11.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/4fdm4yws541djlmflm16vjv40000gn/T/ipykernel_57157/1483296565.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_encoded['Cancer'] = train['Cancer'].values\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([train.drop(columns=['Cancer']), test], axis=0)\n",
    "label_cols = ['Gender', 'Family_Background', 'Radiation_History',\n",
    "              'Iodine_Deficiency', 'Smoke', 'Diabetes', 'Weight_Risk']\n",
    "\n",
    "# 1. Label Encoding 적용할 컬럼\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    all_data[col] = le.fit_transform(all_data[col].astype(str))\n",
    "\n",
    "# 2. One-Hot Encoding 적용할 컬럼\n",
    "one_hot_cols = ['Country', 'Race']\n",
    "\n",
    "all_data = pd.get_dummies(all_data, columns=one_hot_cols)\n",
    "\n",
    "# 다시 train/test로 분할\n",
    "train_encoded = all_data.iloc[:len(train), :]\n",
    "train_encoded['Cancer'] = train['Cancer'].values\n",
    "test_encoded = all_data.iloc[len(train):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830badfd-0843-436e-8890-29576f8190ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [21:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble f1: 0.7055656103850362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "x = train_encoded.drop(['ID', 'Cancer'], axis = 1)\n",
    "y = train_encoded['Cancer']\n",
    "dum_test = test_encoded.drop('ID', axis=1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_split=5, class_weight='balanced_subsample', random_state=42)),\n",
    "        ('xgb', XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "        ('lgb', LGBMClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, class_weight='balanced', random_state=42))\n",
    "    ],\n",
    "    voting='soft',  # 'hard'는 투표 기반, 'soft'는 확률 평균\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ensemble_model.fit(x_train, y_train)\n",
    "pred = ensemble_model.predict(x_test)\n",
    "print('Ensemble f1:', f1_score(y_test, pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2434b3-43c7-4312-8c33-2ba9b83c7ed6",
   "metadata": {},
   "source": [
    "### 앙상블 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e813e1d-d415-46f0-a0c1-d6ac3a9e7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [21:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8367, number of negative: 61360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1161\n",
      "[LightGBM] [Info] Number of data points in the train set: 69727, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 7907, number of negative: 57462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1138\n",
      "[LightGBM] [Info] Number of data points in the train set: 65369, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m x_train, x_val \u001b[38;5;241m=\u001b[39m x_scaled[train_idx], x_scaled[val_idx]\n\u001b[1;32m     56\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_idx], y\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[0;32m---> 58\u001b[0m ensemble_model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     59\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m ensemble_model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n\u001b[1;32m     61\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_val, val_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:366\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    364\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, transformed_y, sample_weight)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:89\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m     90\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[1;32m     91\u001b[0m         clone(clf),\n\u001b[1;32m     92\u001b[0m         X,\n\u001b[1;32m     93\u001b[0m         y,\n\u001b[1;32m     94\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m     95\u001b[0m         message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(names[idx], idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(clfs)),\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clfs)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clf \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. 데이터 분리 및 스케일링\n",
    "x = train_encoded.drop(['ID', 'Cancer'], axis=1)\n",
    "y = train_encoded['Cancer']\n",
    "dum_test = test_encoded.drop(['ID'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "test_scaled = scaler.transform(dum_test)\n",
    "\n",
    "# 2. 개별 모델 정의\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. VotingClassifier 앙상블 구성\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. StratifiedKFold 교차검증 설정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "acc_scores = []\n",
    "test_preds = []\n",
    "\n",
    "# 5. Cross-Validation 루프\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(x_scaled, y)):\n",
    "    x_train, x_val = x_scaled[train_idx], x_scaled[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    ensemble_model.fit(x_train, y_train)\n",
    "    val_pred = ensemble_model.predict(x_val)\n",
    "\n",
    "    f1 = f1_score(y_val, val_pred, average='macro')\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    f1_scores.append(f1)\n",
    "    acc_scores.append(acc)\n",
    "\n",
    "    print(f'Fold {fold+1} F1: {f1:.4f}, Acc: {acc:.4f}')\n",
    "\n",
    "    # 테스트 예측 누적\n",
    "    test_preds.append(ensemble_model.predict_proba(test_scaled))\n",
    "\n",
    "# 6. 평균 성능 출력\n",
    "print(f'\\n[최종 결과]')\n",
    "print(f'평균 F1 score: {np.mean(f1_scores):.4f}')\n",
    "print(f'평균 Accuracy: {np.mean(acc_scores):.4f}')\n",
    "\n",
    "# 7. 테스트 데이터 예측 결과 집계 (소프트보팅 평균)\n",
    "mean_test_pred = np.mean(test_preds, axis=0)\n",
    "final_test_pred = np.argmax(mean_test_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb525b-47ff-49ca-b9ae-d57c79dd793a",
   "metadata": {},
   "source": [
    "# 현재 가장 좋은 성능 !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbdd56c-7608-456e-88eb-9780d6b59f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [09:15:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# 1. Feature, Target 설정\n",
    "x = train_encoded.drop(['ID', 'Cancer'], axis=1)\n",
    "y = train_encoded['Cancer']\n",
    "dum_test = test_encoded.drop(['ID'], axis=1)\n",
    "\n",
    "# 2. 스케일링\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "test_scaled = scaler.transform(dum_test)\n",
    "\n",
    "# 3. 모델 정의\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. 전체 데이터로 모델 학습\n",
    "ensemble_model.fit(x_scaled, y)\n",
    "\n",
    "\n",
    "# 5. 테스트 예측\n",
    "pred = ensemble_model.predict(test_scaled)\n",
    "\n",
    "\n",
    "# 6. 제출 파일 생성\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'Cancer': pred\n",
    "})\n",
    "# 저장\n",
    "#submission.to_csv('final_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db648b-0d31-4644-b5c5-09811e575e5a",
   "metadata": {},
   "source": [
    "# 성능 너무 안좋아서 버림 (smote+Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfff05ad-f12b-4b81-b75b-a039030d4118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [09:38:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Best Threshold for F1: 0.482\n",
      "🏆 Best F1 Score: 0.453\n",
      "\n",
      "[최적 threshold 적용한 Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     15340\n",
      "           1       0.48      0.42      0.45      2092\n",
      "\n",
      "    accuracy                           0.88     17432\n",
      "   macro avg       0.70      0.68      0.69     17432\n",
      "weighted avg       0.87      0.88      0.87     17432\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14395   945]\n",
      " [ 1203   889]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Feature, Target 설정\n",
    "x = train_encoded.drop(['ID', 'Cancer'], axis=1)\n",
    "y = train_encoded['Cancer']\n",
    "dum_test = test_encoded.drop(['ID'], axis=1)\n",
    "\n",
    "# 2. 데이터 분리 (테스트용)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. 스케일링\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "dum_test_scaled = scaler.transform(dum_test)\n",
    "\n",
    "# 4. SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "x_sm, y_sm = smote.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "# 5. 모델 정의\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('lgb', lgb)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 6. 모델 학습\n",
    "ensemble_model.fit(x_sm, y_sm)\n",
    "\n",
    "# 7. 확률 예측 후 threshold 최적화\n",
    "y_proba = ensemble_model.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(f\"\\n🎯 Best Threshold for F1: {best_threshold:.3f}\")\n",
    "print(f\"🏆 Best F1 Score: {best_f1:.3f}\")\n",
    "\n",
    "# 8. 최적 threshold로 재예측\n",
    "y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "# 9. 평가 출력\n",
    "print(\"\\n[최적 threshold 적용한 Classification Report]\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "\n",
    "# 10. 실제 제출용 예측 (선택)\n",
    "final_pred = (ensemble_model.predict_proba(dum_test_scaled)[:, 1] >= best_threshold).astype(int)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'Cancer': final_pred\n",
    "})\n",
    "# submission.to_csv('final_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c6352-7aa7-43a1-a2d7-6707103a1352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
